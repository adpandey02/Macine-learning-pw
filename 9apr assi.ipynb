{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6023ab5-25c4-493d-8800-80c4cbc1975e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is Bayes' theorem?\n",
    "Bayes' theorem is a mathematical formula that describes the probability of an event,\n",
    "based on prior knowledge of conditions that might be related to the event. \n",
    "It is named after Thomas Bayes, an 18th-century British mathematician who first formulated the theorem.\n",
    "\n",
    "\n",
    "Q2. What is the formula for Bayes' theorem?\n",
    "The formula for Bayes' theorem is:\n",
    "P(A|B) = P(B|A) x P(A) / P(B)\n",
    "where:\n",
    "P(A|B) is the probability of event A given that event B has occurred.\n",
    "P(B|A) is the probability of event B given that event A has occurred.\n",
    "P(A) is the prior probability of event A.\n",
    "P(B) is the prior probability of event B.\n",
    "\n",
    "\n",
    "Q3. How is Bayes' theorem used in practice?\n",
    "Bayes' theorem is used in many fields, including statistics, probability theory, and machine learning. \n",
    "It is often used to update beliefs or predictions based on new information. For example,\n",
    "in medical diagnosis, Bayes' theorem can be used to update the probability of a disease \n",
    "based on the results of a diagnostic test.\n",
    "\n",
    "\n",
    "Q4. What is the relationship between Bayes' theorem and conditional probability?\n",
    "Bayes' theorem is a formula that describes conditional probability. It provides a way to calculate the\n",
    "probability of an event, given some prior knowledge or evidence.\n",
    "\n",
    "\n",
    "Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?\n",
    "The choice of which type of Naive Bayes classifier to use depends on the nature of the problem and\n",
    "the characteristics of the data. The three main types of Naive Bayes classifiers are:\n",
    "Gaussian Naive Bayes: used for continuous data that can be modeled using a Gaussian distribution.\n",
    "Multinomial Naive Bayes: used for discrete data that represents counts or frequencies of events.\n",
    "Bernoulli Naive Bayes: used for binary data that represents the presence or absence of features.\n",
    "\n",
    "\n",
    "Q6. Assignment: You have a dataset with two features, X1 and X2, and two possible classes, A and B.\n",
    "You want to use Naive Bayes to classify a new instance with features X1 = 3 and X2 = 4.\n",
    "The following table shows the frequency of each feature value for each class:   \n",
    "Class X1=1 X1=2 X1=3 X2=1 X2=2 X2=3 X2=4\n",
    "A       3   3    4    4     3    3    3\n",
    "B       2   2    1    2     2    2    3\n",
    "\n",
    "Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new \n",
    "instance to belong to?\n",
    "\n",
    "To classify the new instance using Naive Bayes, we need to calculate the likelihood of the features\n",
    "given each class and multiply it by the prior probability of the class. Then, we normalize the \n",
    "result to obtain the posterior probability of each class.\n",
    "\n",
    "The likelihood of the features given each class can be calculated using the frequency table:\n",
    "\n",
    "P(X1=3|A) = 4/10 = 0.4\n",
    "P(X2=4|A) = 3/10 = 0.3\n",
    "P(X1=3|B) = 1/7 ≈ 0.143\n",
    "P(X2=4|B) = 1/7 ≈ 0.143\n",
    "\n",
    "The prior probability of each class is assumed to be 0.5, since there are two possible classes \n",
    "and we have no reason to believe one is more likely than the other.\n",
    "\n",
    "Using the formula for Naive Bayes classification, we can calculate the posterior probability of\n",
    "each class for the new instance:\n",
    "\n",
    "P(A|X1=3,X2=4) = P(X1=3|A) x P(X2=4|A) x P(A) / P(X1=3,X2=4)\n",
    "= 0.4 x 0.3 x 0.5 / P(X1=3,X2=4)\n",
    "\n",
    "P(B|X1=3,X2=4) = P(X1=3|B) x P(X2=4|B) x P(B) / P(X1=3,X2=4)\n",
    "= 0.143 x 0.143 x 0.5 / P(X1=3,X2=4)\n",
    "\n",
    "To calculate P(X1=3,X2=4), we can use the law of total probability:\n",
    "\n",
    "P(X1=3,X2=4) = P(X1=3,X2=4|A) x P(A) + P(X1=3,X2=4|B) x P(B)\n",
    "= 0.4 x 0.3 x 0.5 + 0.143 x 0.143 x 0.5\n",
    "≈ 0.0318\n",
    "\n",
    "Substituting this value into the above equations, we get:\n",
    "\n",
    "P(A|X1=3,X2=4) ≈ 0.6\n",
    "P(B|X1=3,X2=4) ≈ 0.4\n",
    "\n",
    "Therefore, Naive Bayes would predict the new instance to belong to class A, since it has a \n",
    "higher posterior probability.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
