{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933b8a60-84e4-435c-9d13-3f2049b80b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. Simple linear regression involves predicting a dependent variable y based on a single independent \n",
    "variable x. In contrast, multiple linear regression involves predicting y based on multiple independent\n",
    "variables x1, x2, x3, and so on. An example of simple linear regression could be predicting the \n",
    "sales of a product based on the advertising budget for that product. An example of multiple linear\\\n",
    "regression could be predicting the price of a house based on its size, number of bedrooms, and location.\n",
    "\n",
    "Q2. The assumptions of linear regression include linearity, independence, normality, \n",
    "and equal variance. You can check whether these assumptions hold in a given dataset by \n",
    "plotting the residuals (the difference between the predicted values and the actual values) \n",
    "against the predicted values and checking for patterns or trends. You can also perform hypothesis \n",
    "tests to check whether the residuals are normally distributed and have equal variance.\n",
    "\n",
    "Q3. The slope in a linear regression model represents the change in the dependent variable for \n",
    "a one-unit change in the independent variable. The intercept represents the value of the dependent\n",
    "variable when the independent variable is zero. For example, in a simple linear regression model\n",
    "that predicts the sales of a product based on the advertising budget, the slope would represent \n",
    "the increase in sales for every additional dollar spent on advertising, and the intercept would\n",
    "represent the predicted sales when no money is spent on advertising.\n",
    "\n",
    "Q4. Gradient descent is an optimization algorithm that is used to find the minimum value of a\n",
    "function by iteratively adjusting the parameters in the direction of steepest descent. \n",
    "In machine learning, gradient descent is used to minimize the cost function, which measures \n",
    "the difference between the predicted values and the actual values. By minimizing the cost\n",
    "function, the model can find the best values for the parameters that will result in accurate predictions.\n",
    "\n",
    "Q5. Multiple linear regression is a statistical model that predicts a dependent variable based \n",
    "on multiple independent variables. In contrast to simple linear regression, which has only one \n",
    "independent variable, multiple linear regression can account for the effects of multiple variables\n",
    "on the dependent variable. Multiple linear regression models can be used to analyze complex \n",
    "relationships between variables, and to identify the most important predictors of the dependent variable.\n",
    "\n",
    "Q6. Multicollinearity occurs when two or more independent variables in a multiple linear\n",
    "regression model are highly correlated with each other. This can lead to problems in the \n",
    "model, such as coefficients that are difficult to interpret or unstable. To detect multicollinearity, \n",
    "you can calculate the correlation matrix of the independent variables and check for high correlations.\n",
    "To address multicollinearity, you can remove one of the correlated variables from the model,\n",
    "or you can use regularization techniques such as ridge regression or lasso regression.\n",
    "\n",
    "Q7. Polynomial regression is a form of regression analysis in which the relationship between\n",
    "the dependent variable and the independent variable is modeled as an nth-degree polynomial.\n",
    "In contrast to linear regression, which models a linear relationship between the variables,\n",
    "polynomial regression can model nonlinear relationships. For example, a quadratic polynomial \n",
    "regression model could be used to predict the height of a ball thrown in the air based on the\n",
    "time since it was thrown.\n",
    "\n",
    "Q8. The advantage of polynomial regression over linear regression is that it can capture nonlinear \n",
    "relationships between the variables. However, polynomial regression can also be prone to overfitting,\n",
    "especially for high-degree polynomials, which can result in poor generalization to new data. \n",
    "Polynomial regression is useful in situations where the relationship between the variables is\n",
    "nonlinear, but it should be used with caution and validated carefully"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
