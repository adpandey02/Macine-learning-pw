{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7524c7b-9cdc-419a-b823-75b3bdfb6bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q1. Elastic Net Regression is a regularization technique used in linear regression that combines \n",
    "the penalties of both Lasso Regression and Ridge Regression. It helps to prevent overfitting by \n",
    "shrinking the coefficients of less important features towards zero while also allowing for the\n",
    "inclusion of multiple correlated predictors in the model. Unlike Lasso Regression and Ridge Regression,\n",
    "Elastic Net Regression uses two tuning parameters: alpha, which controls the balance between\n",
    "L1 and L2 penalties, and lambda, which controls the strength of the penalty term\n",
    "\n",
    "Q2. The optimal values of the regularization parameters for Elastic Net Regression can be chosen\n",
    "using techniques such as cross-validation or grid search, where different values of alpha and \n",
    "lambda are tested on the training data, and the combination that produces the best performance \n",
    "on the validation set is selected as the optimal value\n",
    "\n",
    "Q3. The advantages of Elastic Net Regression include its ability to handle high-dimensional data\n",
    "with many correlated predictors, its robustness to outliers and missing values, and its ability \n",
    "to perform both feature selection and parameter estimation. However, one disadvantage of Elastic\n",
    "Net Regression is that it can be computationally expensive and may require a large amount of memory\n",
    "to fit the model, especially for very large datasets\n",
    "\n",
    "Q4. Some common use cases for Elastic Net Regression include gene expression analysis, image analysis,\n",
    "and prediction of clinical outcomes based on multiple biological and clinical predictors\n",
    "\n",
    "Q5. The coefficients in Elastic Net Regression can be interpreted in the same way as other\n",
    "regression techniques, as the contribution of each input feature to the target variable, \n",
    "after taking into account the effect of all other features in the model. \n",
    "A positive coefficient means that the feature has a positive effect on the target variable,\n",
    "while a negative coefficient means the opposite\n",
    "\n",
    "Q6. One way to handle missing values when using Elastic Net Regression is to impute the missing \n",
    "values with the mean or median of the non-missing values before fitting the model. \n",
    "Another approach is to use algorithms such as the Iterative Imputation Algorithm or the \n",
    "k-Nearest Neighbors Imputation Algorithm to estimate the missing values.\n",
    "\n",
    "Q7. Elastic Net Regression can be used for feature selection by setting the L1 penalty (alpha=1) \n",
    "to force some of the coefficients to be zero. The non-zero coefficients represent the most\n",
    "important features in the model, and can be used to select a subset of the input features for\n",
    "further analysis or modeling.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070654d9-f5a6-4af2-a3c9-20824a67fcf3",
   "metadata": {},
   "source": [
    "## 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a56629f9-db41-44a6-9525-0e59cfc6ba92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.42466891 11.28766554]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "import pickle\n",
    "\n",
    "# Example X and y training data\n",
    "X_train = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
    "y_train = [10, 11, 12]\n",
    "\n",
    "# Train and fit Elastic Net Regression model\n",
    "model = ElasticNet(alpha=0.5, l1_ratio=0.5)   # alpha -- ridge param , l1_ratio -- lasso param\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Save the model to a file\n",
    "with open('model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "# Load the model from the file\n",
    "with open('model.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "    \n",
    "# Make predictions using the loaded model\n",
    "X_test = [[2, 3, 4], [5, 6, 7]]\n",
    "y_pred = model.predict(X_test)\n",
    "print(y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67285835-a0c3-4bd1-83d8-cf1f26dd123e",
   "metadata": {},
   "source": [
    "## 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedee562-be38-46cc-be8f-0efa42346bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The purpose of pickling a model in machine learning is to save a trained model to disk and be\n",
    "able to reuse it later without having to retrain the model. This is useful when the training \n",
    "process is computationally expensive and time-consuming, or when the model needs to be deployed\n",
    "to a production environment where it will be used to make predictions on new data. \n",
    "Pickling allows the model to be easily saved and loaded, so that it can be used again and again\n",
    "without having to go through the training process each time\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
