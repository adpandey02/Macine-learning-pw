{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b03394b-d3eb-43df-8cb4-d841e68ea9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1.Eigenvalues and Eigenvectors are important concepts in linear algebra and are closely related to\n",
    "the Eigen-Decomposition approach. Eigenvalues represent the scaling factor of an eigenvector when a \n",
    "matrix is multiplied by it. Eigenvectors are non-zero vectors that only change in magnitude when a \n",
    "linear transformation is applied to them. The Eigen-Decomposition approach is a technique used to \n",
    "decompose a matrix into its eigenvectors and eigenvalues.\n",
    "\n",
    "Q2. # Eigen decomposition is the process of decomposing a square matrix into a set of eigenvectors and \n",
    "eigenvalues. The significance of eigen decomposition in linear algebra is that it can simplify certain\n",
    "matrix operations. It can also be used to diagonalize a matrix, which makes it easier to perform \n",
    "operations like matrix inversion.\n",
    "\n",
    "Q3.For a square matrix to be diagonalizable using the Eigen-Decomposition approach, it must have \n",
    "linearly independent eigenvectors, equal to the dimension of the matrix. This means that the matrix\n",
    "must be diagonalizable if and only if it has n distinct eigenvalues\n",
    "\n",
    "Q4.The spectral theorem states that any real symmetric matrix can be diagonalized by an orthogonal \n",
    "matrix. In the context of the Eigen-Decomposition approach, this means that a real symmetric matrix\n",
    "can always be diagonalized using its eigenvectors. The significance of the spectral theorem is that\n",
    "it provides a powerful tool for simplifying certain matrix operations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3e2e74-50bd-4d81-80d1-c72cff52d039",
   "metadata": {},
   "source": [
    "## 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c7a498d-6b7a-46f4-9bd1-e0769480cb91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3. 1.]\n"
     ]
    }
   ],
   "source": [
    "# this is how eigrnvalues and eigenvectors can be clculated using python\n",
    "# it can also be calculated manually on pen and paper but its too long process\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Create a matrix\n",
    "A = np.array([[2, 1], [1, 2]])\n",
    "\n",
    "# Calculate the eigenvalues\n",
    "eigvals, _ = np.linalg.eig(A)\n",
    "\n",
    "print(eigvals)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449ee073-5bdb-463a-8d77-b25633eae3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. Eigenvectors are the non-zero vectors that are only scaled by a scalar factor when a linear\n",
    "transformation is applied to them. They are related to eigenvalues as the eigenvalues represent \n",
    "the scaling factor for the corresponding eigenvectors.\n",
    "\n",
    "Q7. The geometric interpretation of eigenvectors and eigenvalues can be understood as follows.\n",
    "When a matrix is applied to an eigenvector, the resulting vector is only scaled by a scalar factor\n",
    "which is the corresponding eigenvalue. Therefore, the eigenvector represents the direction of the\n",
    "transformation, while the eigenvalue represents the scaling factor. In other words, the eigenvector\n",
    "tells us the direction along which the transformation stretches or compresses the data, while\n",
    "the eigenvalue tells us by how much.\n",
    "\n",
    "Q8. Eigen decomposition has a wide range of real-world applications, some of which include:\n",
    "Principal Component Analysis (PCA): Used for dimensionality reduction and feature extraction.\n",
    "Image compression: Used to compress digital images by representing the image as a linear combination \n",
    "of its eigenvectors.\n",
    "Markov Chain Analysis: Used to analyze and predict future states of a system that evolves over time.\n",
    "\n",
    "Q9. yes\n",
    "\n",
    "Q10. Eigen-Decomposition approach is useful in data analysis and machine learning in various ways. \n",
    "Three specific applications or techniques that rely on Eigen-Decomposition are:\n",
    "Principal Component Analysis (PCA): Used for dimensionality reduction and feature extraction.\n",
    "Singular Value Decomposition (SVD): Used for matrix factorization and feature extraction.\n",
    "Linear Discriminant Analysis (LDA): Used for dimensionality reduction and feature extraction \n",
    "in the context of classification problems.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
