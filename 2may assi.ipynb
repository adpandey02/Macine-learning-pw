{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1876b6a8-f027-4638-8893-676b3a5f3a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is anomaly detection and what is its purpose?\n",
    "Anomaly detection is the process of identifying rare or unusual events, patterns, or observations \n",
    "in a dataset that deviate significantly from the norm or expected behavior. The purpose of \n",
    "anomaly detection is to identify these anomalies or outliers, which may be indicative of \n",
    "fraud, errors, or anomalies in the data, and require further investigation or action.\n",
    "\n",
    "Q2. What are the key challenges in anomaly detection?\n",
    "There are several challenges in anomaly detection, including:\n",
    "Defining what constitutes normal behavior or expected patterns in the data.\n",
    "Determining the appropriate threshold or level of abnormality to flag an observation as an anomaly.\n",
    "Dealing with imbalanced datasets where the number of normal observations greatly exceeds the number\n",
    "of anomalous observations.\n",
    "Handling high-dimensional data where the number of features or dimensions is large.\n",
    "Addressing the issue of concept drift, where the underlying data distribution may change over time.\n",
    "\n",
    "Q3. How does unsupervised anomaly detection differ from supervised anomaly detection?\n",
    "Unsupervised anomaly detection is a type of anomaly detection that does not require labeled data \n",
    "and relies on the assumption that anomalies are rare and significantly different from the normal \n",
    "data points. It uses statistical methods or machine learning algorithms to identify data points\n",
    "that are significantly different from the rest of the data. In contrast, supervised anomaly \n",
    "detection requires labeled data with known anomalies and uses machine learning algorithms to \n",
    "learn a model that can distinguish between normal and anomalous data points.\n",
    "\n",
    "Q4. What are the main categories of anomaly detection algorithms?\n",
    "The main categories of anomaly detection algorithms include:\n",
    "Statistical methods: These methods use statistical models to detect anomalies based on the probability\n",
    "distribution of the data. Machine learning methods: These methods use machine learning algorithms\n",
    "to learn patterns in the data and identify anomalies based on deviations from these patterns.\n",
    "Distance-based methods: These methods use distance or similarity measures to identify data points\n",
    "that are significantly different from the rest of the data.\n",
    "Clustering-based methods: These methods use clustering algorithms to identify groups of data points\n",
    "that are significantly different from the rest of the data.\n",
    "\n",
    "Q5. What are the main assumptions made by distance-based anomaly detection methods?\n",
    "Distance-based anomaly detection methods assume that anomalies are data points that are significantly\n",
    "distant or dissimilar from the rest of the data. These methods typically use a distance or \n",
    "similarity measure, such as Euclidean distance or cosine similarity, to calculate the distance\n",
    "between each data point and its neighbors. Anomalies are identified as data points that have a\n",
    "large distance or dissimilarity from their neighbors.\n",
    "\n",
    "Q6. How does the LOF algorithm compute anomaly scores?\n",
    "The LOF (Local Outlier Factor) algorithm computes anomaly scores by measuring the local density of\n",
    "each data point and comparing it to the local densities of its neighbors. The algorithm first \n",
    "calculates the k-distance of each data point, which is the distance to its k-th nearest neighbor\n",
    "It then calculates the local reachability density (LRD) of each data point, which is the inverse \n",
    "of the average k-distance of its k nearest neighbors. Finally, the algorithm calculates the LOF \n",
    "of each data point, which is the ratio of the LRD of a data point to the LRD of its neighbors\n",
    "Data points with an LOF greater than 1 are considered anomalous.\n",
    "\n",
    "Q7. What are the key parameters of the Isolation Forest algorithm?\n",
    "The key parameters of the Isolation Forest algorithm are:\n",
    "n_estimators: the number of trees in the forest.\n",
    "max_samples: the number of samples to draw from the dataset to build each tree.\n",
    "max_depth: the maximum depth of each tree.\n",
    "contamination: the proportion of anomalies in the dataset.\n",
    "\n",
    "Q8.there is not enough information to calculate it\n",
    "\n",
    "Q9.The anomaly score for this data point would be calculated as (2^(-5.0/avg_path_length_dataset))\n",
    "where avg_path_length_dataset is the average path length for all the data points in the dataset\n",
    "but avg_path_length_dataset is not given in the question"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
