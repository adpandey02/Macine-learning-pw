{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e67db6-e0ca-41a5-a04b-fbaee4064551",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q1. Ridge regression is a linear regression technique that adds a penalty term to the ordinary \n",
    "least squares regression. The penalty term is equal to the square of the coefficients multiplied \n",
    "by a tuning parameter (lambda). This penalty term shrinks the coefficients towards zero and \n",
    "reduces the variance of the estimates. Ridge regression is different from ordinary least squares\n",
    "regression because it adds a penalty term that limits the magnitude of the coefficients.\n",
    "\n",
    "Q2. The assumptions of ridge regression are the same as ordinary least squares\n",
    "regression: linearity, independence, homoscedasticity, and normality. Additionally,\n",
    "ridge regression assumes that there is some amount of multicollinearity among the independent variables.\n",
    "\n",
    "Q3. The value of the tuning parameter (lambda) in ridge regression can be selected using \n",
    "cross-validation. A range of values for lambda can be tested, and the one that produces the\n",
    "lowest cross-validation error can be chosen.\n",
    "\n",
    "Q4. Ridge regression can be used for feature selection by shrinking the coefficients of the\n",
    "less important features towards zero. Features with small coefficients can be removed from the\n",
    "model, effectively performing feature selection.\n",
    "\n",
    "Q5. Ridge regression performs well in the presence of multicollinearity because it reduces the\n",
    "variance of the estimates by shrinking the coefficients towards zero.\n",
    "This reduces the impact of multicollinearity on the estimates.\n",
    "\n",
    "Q6. Ridge regression can handle both categorical and continuous independent variables. \n",
    "Categorical variables can be represented using dummy variables.\n",
    "\n",
    "Q7. The coefficients of ridge regression can be interpreted in the same way as ordinary \n",
    "least squares regression. A positive coefficient indicates a positive relationship between\n",
    "the independent variable and the dependent variable, while a negative coefficient indicates\n",
    "a negative relationship. The magnitude of the coefficient indicates the strength of the relationship.\n",
    "\n",
    "Q8. Ridge regression can be used for time-series data analysis by including lagged \n",
    "values of the dependent variable and independent variables as predictors. \n",
    "The same assumptions and techniques for selecting the tuning parameter apply \n",
    "to time-series data as well. Additionally, care must be taken to ensure that the\n",
    "time-series data is stationary before applying ridge regression.\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
